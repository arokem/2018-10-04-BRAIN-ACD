<!doctype html>
<html>
	<head>
		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
		<meta name="description" content="Talk at UW PBIO, May 24th, 2018">
		<meta name="author" content="Ariel Rokem">

		<title> Challenges and opportunities for computational neuroscience </title>

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/arokem.css">

		<!-- Theme used for syntax highlighting of code -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- Printing and PDF exports -->
		<script>
			var link = document.createElement( 'link' );
			link.rel = 'stylesheet';
			link.type = 'text/css';
			link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
			document.getElementsByTagName( 'head' )[0].appendChild( link );
		</script>

		<script>
            function canvas_arrow_two_heads(context, fromx, fromy, tox, toy){
                let headlen = 10;   // length of head in pixels
                let angle = Math.atan2(toy-fromy,tox-fromx);
                context.moveTo(fromx, fromy);
                context.lineTo(fromx+headlen*Math.cos(angle+Math.PI/6),fromy+headlen*Math.sin(angle+Math.PI/6));
                context.moveTo(fromx, fromy);
                context.lineTo(fromx+headlen*Math.cos(angle-Math.PI/6),fromy+headlen*Math.sin(angle-Math.PI/6));
                context.moveTo(fromx, fromy);
                context.lineTo(tox, toy);
                context.lineTo(tox-headlen*Math.cos(angle-Math.PI/6),toy-headlen*Math.sin(angle-Math.PI/6));
                context.moveTo(tox, toy);
                context.lineTo(tox-headlen*Math.cos(angle+Math.PI/6),toy-headlen*Math.sin(angle+Math.PI/6));}
		</script>

	</head>
	<body>
	<div class="reveal">
	<div class="slides">

	<section>
		<em>
		<h2> The era of brain observatories </h2>
		<h3><div align=middle> Challenges and opportunities for computational neuroscience </div></h3>
		</em>
		<br>October, 4th 2018
		<br>BRAIN Initiative Working Group 2.0 Workshop
		<p><a href="http://arokem.org">Ariel Rokem</a>,
		<a href="http://escience.washington.edu">The University of Washington eScience Institute</a> </p>
		<p>  <small>Follow along at: <t><a href="https://arokem.github.io/2018-05-24-uw-pbio/#/">https://arokem.github.io/2018-05-24-uw-pbio</t></a></small></p>

		<img src="img/eScience.png" height="100px" alt="eScience logo" align="middle">
		<img src="img/uwin-logo.jpg" height="100px" alt="CNC logo" align="middle">
		<img src="img/cnc.png" height="100px" alt="CNC logo" align="middle">
		<br>
		<img src="img/cc-by.png" height="30px" alt="License" align="middle">
	</section>

	<section>		

		<div style="position: absolute; left:0.1em; top">
			<img src="img/brain_icon.png" height=100>
		</div>
		<div class="fragment" style="position: absolute; left:7em; top:-4em;">
			<video height="100" autoplay loop muted>
				<source src="img/em.mp4">
			</video>
		</div>

		<div class="fragment" style="position: absolute; left:7em; top:0em;">
				<video height="100" autoplay loop muted>
					<source src="img/mouse_brain_lsm.mp4">
				</video>
		</div>

		<div class="fragment" style="position: absolute; left:6em; top:3.5em;">
				<video id="MRIvideo" height="150" autoplay loop muted style="playbackRate:0.5;">
					<source src="img/mri-zstack.mov">
				</video>
		</div>
		<!-- Slow down the MRI video-->
		<script>
				var vid = document.getElementById("MRIvideo");
				vid.playbackRate = 0.5;
		</script> 

		<div class="cite">
			<a href=""></a>
		</div>

	</section>
	


	<section data-background-image="./img/radio-astronomy-survey.png" data-background-size="cover">
		<blockquote  style="background: rgba(255, 255, 255, 0);">
			<p style="color:#FFFFFF";>The era of brain observatories</p>
		</blockquote>
	</section>


	<section data-background-video="./img/allen_institute_spinning_cells.mp4" data-background-size="cover">
		<blockquote  style="background: rgba(255, 255, 255, 0);">
			<p style="color:#FFFFFF";>Allen Institute for Brain Science</p>
		</blockquote>
	</section>

	<section data-background-image="./img/hcplogo1.jpg" data-background-size="1000px">
		<p style="position: absolute; left:760px; top:400px;"; >n=1200</p>
	</section>

	<section>
		<div>
		<img src="img/child-mind-institute-hbn-logo.jpg">
		<br>
		n=~10,000
		</div>
		<div class="fragment">
		<img src="img/abcd-logo.png">
		<br>
		n=~10,000
		</div>
	</section>
	<section data-background-image="./img/UKBiobank_Brain_Imaging.001.jpeg" data-background-size="1000px" data-background-color="black">
		<p style="position: absolute; left:760px; top:600px;"; >n=500,000</p>
	</section>


	
	<section>
		<h2>Opportunities</h2>
		<p class="fragment">New data sets will enable important new discoveries</p>
		<p class="fragment">New methods</p>
		<p class="fragment">Data-driven discovery</p>
	</section>

	<section>
		<h2>Challenges</h2>
		<p class="fragment">Methods that work in standard use may not apply to large datasets</p>
		<p class="fragment">=> Train machine learning algorithms to replace expert decision making</p>
		<p class="fragment">Tools are needed for data exploration and transparent sharing of results</p>
		<p class="fragment">=> Build browser-based applications for exploratory data analysis and data sharing </p>
		<p class="fragment">Algorithms are needed to extract information from complex high-dimensional data</p>
		<p class="fragment">=> Translate statistical techniques into practice in neuroscience</p>
		<p class="fragment">Sociotechnical structures are strained: collaboration, publication, training</p>
		<p class="fragment">=> Open source software collaborations and science-focused hack weeks</p>
	</section>

	<!--


	<section>
		<h2>The IXI dataset</h2>
		<p>~700 subjects</p>
		<p>Three different scanners</p>
		<p> Several different MRI modailities</p>
		<p> Preprocessed and co-registered </p>
		<a href="http://brain-development.org/ixi-dataset/">http://brain-development.org/ixi-dataset/</a>
		<p class="fragment">Can we find the correspondence between imaging contrasts?</p>
	</section>

	<section>
		<h2> Imaging contrasts</h2>
		<img src="img/t1_t2.png" height="400">
	</section>

	<section>
		<h2> Imaging contrasts</h2>
		<img src="./img/t2t1_rsquared.png">

	</section>

	<section>
		<div align=center><h4>Optical Coherence Tomography (OCT)</h4>
			High-fidelity <em> in vivo </em> measurements of retinal structure at micron resolution
			<div class="fragment" align="middle">
				<image src="img/OCT.png" width="400px">
			</div>
			<div class="fragment" align="middle">
				<image src="img/OCT-irf.png" width="400px">
			</div>
	</section>

	<section>
		<img src="img/UNET.png">

		<div class=cite>
			<a href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/">Ronneberger et al. 2015</a>
		</div>

	</section>


	<section>
		<h4>OCT => OCTA </h4>
		<img src="img/oct2octa.png" height=500px>
		<div class=cite>
			<a href="https://www.biorxiv.org/content/early/2018/02/25/271346">Lee et al. (2018)</a>
		</div>
	</section>
	<section>
		<h4>OCT => OCTA </h4>
		<img src="img/oct2octa_cues.png">
		<div class=cite>
			<a href="https://www.biorxiv.org/content/early/2018/02/25/271346">Lee et al. (2018)</a>
		</div>
	</section>

	<section>
		<h4>MRI => MRI </h4>
		<video width="800" autoplay loop>
			<source src="img/t2t1.mov">
		</video>
		<div class="cite">
			<br>
			<a href="https://www.biorxiv.org/content/early/2018/03/27/289926">Xiao, Wu, Lee & Rokem <br>(<em>in prep</em>)</a>
		</div>
	</section>

	<section>
		<h4>MRI => MRI </h4>
		<img src="./img/t2t1_rsquared.png">
		<div class="cite">
			<a href="https://www.biorxiv.org/content/early/2018/03/27/289926">Xiao, Wu, Lee & Rokem <br>(<em>in prep</em>)</a>
		</div>
	</section>

	<section>
		<h4>MRI => MRI </h4>
		<img src="./img/t2t1_synth_rsquared.png">
		<div class="cite">
			<a href="https://www.biorxiv.org/content/early/2018/03/27/289926">Xiao, Wu, Lee & Rokem <br> (<em>in prep</em>)</a>
		</div>
	</section>

	<section>
		<h4>MRI => MRI </h4>
		<img src="img/t2t1_model_comparison.png">
		<div class="cite">
			<a href="https://www.biorxiv.org/content/early/2018/03/27/289926">Xiao, Wu, Lee & Rokem <br> (<em>in prep</em>)</a>
		</div>

	</section>
	<section>
		<h3>Does it generalize?</h3>
	</section>

	<section>
		<h3>1.5T MRI => 3T MRI</h3>
		<img src="img/t2t1_model_comparison_with_generalization.png">
		<div class="cite">
			<a href="https://www.biorxiv.org/content/early/2018/03/27/289926">Xiao, Wu, Lee & Rokem <br> (<em>in prep</em>)</a>
		</div>

	</section>

	<section>
		<h2 >Application: cross-modal image registration</h2>
		<img src="./img/dti_reg.png" height=400>
	</section>

	<section>
		<h2 >Application: cross-modal image registration</h2>
		<img src='img/compare_registrations.png'>
		<div class="cite">
			<a href="https://www.biorxiv.org/content/early/2018/03/27/289926">Xiao, Wu, Lee & Rokem <br> (<em>in prep</em>)</a>
		</div>
	</section>

	<section>
		<h2>Summary</h2>
		<p class="fragment">Convolutional neural networks can be used for cross-modal MR image synthesis</p>
		<p class="fragment">Useful for image registration</p>

	</section>

	<section>
		<h2>Future applications</h2>
		<p class="fragment"> Cross-modal registration in other data</p>
		<p class="fragment"> Transcriptomic imaging </p>
		<p class="fragment"> Digital histology</p>
	</section>
	-->

	<section>
		<h4>Challenge: Methods that work in standard datasets may fail in Big Data</h4>
		<p class="fragment">Some methods require expert examination</p>
		<p class="fragment">Time consuming, tedious</p>
		<p class="fragment">=> Do not scale well!</p>
	</section>


	<section>
		<h2>The solution</h2>
		<p class="fragment">Expert => results</p>
		<p class="fragment">Expert => training data => machine learning => results</p>

	</section>

	<section>
		<h3>Learning to replace experts</h3>
		<div style="position: absolute; left:80px; top:60px;">
			<img src="img/aaron.jpeg" height="200">
			<br>
			Aaron Lee
		</div>

		<div style="position: absolute; left:260px; top:60px;">
			<img src="img/sa.jpeg" height="200">
			<br>
			Sa Xiao
		</div>


		<div style="position: absolute; left:480px; top:60px;">
			<img src="img/parmita.jpeg" height="200">
			<br>
			Parmita <br>Mehta
		</div>

		<div style="position: absolute; left:700px; top:60px;">
			<img src="img/magda_sm.jpg" height="200">
			<br>
			Magda <br>Balazinska
		</div>

	</section>


	<section>
		<h4>The UW OCT/EMR data-base</h4>
		<div class="fragment" style="position: absolute; left: 10px; top: 55px;" >
			<p>
				10 years (2006-2016)
			<p>
				9,285 patients
			<p>
				43,328 OCT volumes
			<p>
				2.64 million OCT images
			<p>
				2.5 TB of data
		</div>
		<div class="fragment" style="position: absolute; left: 400px; top: 55px;" >
			<p>Linked to <E></E>PIC electronic medical records
			<p> For each OCT we know:
				<small>
			<p> Visual acuity
			<p> OCT interpretation
			<p> Diagnosis
			<p> Treatment determinations
			<p> In some cases - longitudinal measurements
				</small>
		</div>
	</section>

	<section>
		<h2>Artificial neural networks</h2>
		<p class="fragment">A family of machine learning algorithms</p>
		<p class="fragment">Biologically inspired</p>
		<div class="cite">
			<a href="https://www.nature.com/articles/nature14539">LeCun et al. 2015</a>
		</div>
	</section>

	<section>

		<h2>Artificial neural networks</h2>
		<img src="img/minsky_papert.png">
		<div class="cite">Minsky and Papert (1969)</div>
	</section>

	<section>
		<h2> Artificial neural networks</h2>
		<p>A family of machine learning algorithms</p>
		<p>Biologically inspired</p>
		<p class="fragment">Implement a cascade of linear/non-linear operations</p>
		<div class="cite">
			<a href="https://www.nature.com/articles/nature14539">LeCun et al. 2015</a>
		</div>
	</section>

	<section>
		<img src="img/simple-network.png">
		<div class="cite">
			<a href="https://www.nature.com/articles/nature14539">LeCun et al. 2015</a>
		</div>
	</section>


	<section>
		<h2> Convolutional networks</h2>
		<p class="fragment">Capitalize on spatial correlations in images</p>
		<p class="fragment">Inspired by the mammalian visual system</p>

		<div class="cite">
			<a href="https://www.nature.com/articles/nature14539">LeCun et al. 2015</a>
		</div>

	</section>

	<section>
		<img src="img/bosking.jpg" height=500>

		<div class="cite">
			<a href="http://www.jneurosci.org/content/17/6/2112.long">Bosking et al. 1997</a>
		</div>

	</section>


	<section>
		<img src="img/imagenet-fig4l.png">
		<div class=cite>
			<a href="http://www.cs.toronto.edu/~fritz/absps/imagenet.pdf">Krizhevsky et al. 2012</a>
		</div>
	</section>



	<!--
	<section>
		<img src="img/convolution_animation.gif">

		<div class="cite">
			<a href="https://arxiv.org/abs/1603.07285">Dumoulin and Visin (2016)</a>
		</div>
	</section>


	-->


	<section>
		<h4>Deep learning accurately classifies age-related macular degeneration (AMD) </h4>
		<img src="img/amd-vgg16-results.png" height=400px>
		<br>
		Patient-level AUC = 0.97
		<div class=cite>
			<a href="https://www.ophthalmologyretina.com/article/S2468-6530(16)30174-9">Lee et al. (2016)</a>
		</div>

	</section>

	<!--
	<section>
		<h4><div align="center">Is there a ball in the picture?</div></h4>
		<image src="img/dog-with-ball.png" height="400px">
			<div class=cite>
				><a href="https://arxiv.org/pdf/1311.2901.pdf">Zeiler and Fergus (2013)</a>
			</div>
	</section>

	<section>
		<h4><div align="center">How about now?</div></h4>
		<image src="img/dog-with-ball-occluder-corner.png" height="400px">
			<div class=cite>
				><a href="https://arxiv.org/pdf/1311.2901.pdf">Zeiler and Fergus (2013)</a>
			</div>
	</section>

	<section>
		<h4><div align="center">And now?</div></h4>
		<image src="img/dog-with-ball-occluder-center.png" height="400px">

			<div class=cite>
				<a href="https://arxiv.org/pdf/1311.2901.pdf">Zeiler and Fergus (2013)</a>
			</div>
	</section>

	<section>
		<h4><div align="center">Deep learning network identifies clinical features</div></h4>
		<image src="./img/amd-vgg16-occlusion.png" height="500px">
			<div class=cite>
				<a href="">Lee et al. (2016)</a>
			</div>
	</section>
	-->

	<section>
		<h4>Solving multi-class multi-label problems</h4>
		<p class="fragment">Binary classification doesn't model clinical decision making </p>
		<p class="fragment">Patients can have any of a several diseases</p>
		<p class="fragment">Or more than one disease</p>
		<p class="fragment"> => Train several networks and integrate across them</p>
		<div class=cite>
			<a href="https://www.biorxiv.org/content/early/2018/05/08/316349">Mehta, Lee, Lee, Balazinska & Rokem <br> (<em>in review</em>)</a>
		</div>

	</section>

	<section>
		<h4>Augmenting the neural network with additional patient information</h4>
		<img src="img/multi_class_multi_label.png">
		<div class=cite>
			<a href="https://www.biorxiv.org/content/early/2018/05/08/316349">Mehta, Lee, Lee, Balazinska & Rokem <br> (<em>in review</em>)</a>
		</div>
	</section>

	<!--
	<section>
		<h2>Fully convolutional networks</h2>

		Take an image as input and produce an image as output


		<section>
			<img src="img/unet-architecture.png" height=500px>
			<div class=cite>
				<a href="https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/">Ronneberger et al. 2015</a>
			</div>
		</section>
	-->


	<section>
		<h4><div align="center">Detecting clinical features: intraretinal fluid segmentation</div></h4>
		<image src="./img/unet-segmentation-1.png" height="500px">
			<div style="position: absolute; left: 700px; top: 620px" >
				<small><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5508840/">Lee, Tyring, Deruyter, Wu, Rokem & Lee (2016)<br> Biomed opt Express</a>
				</small>
			</div>
	</section>

	<section>
		<h4><div align="center">Detecting clinical features: intraretinal fluid segmentation</div></h4>
		<image src="./img/unet-segmentation-2.png" height="500px">
			<div style="position: absolute; left: 700px; top: 620px" >
				<small><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5508840/">Lee, Tyring, Deruyter, Wu, Rokem & Lee (2016)<br> Biomed opt Express</a>
				</small>
			</div>
	</section>

	<section>
		<h4><div align="center">Detecting clinical features: intraretinal fluid segmentation</div></h4>
		<image src="./img/unet-vs-humans.png" height="500px">
			<div style="position:absolute; left:580px;top:70px">
				<image src="./img/white-square.png" height="500px">
			</div>
			<div style="position: absolute; left: 700px; top: 620px" >
				<small><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5508840/">Lee, Tyring, Deruyter, Wu, Rokem & Lee (2016)<br> Biomed opt Express</a>
				</small>
			</div>
	</section>

	<section>
		<h4><div align="center">Detecting clinical features: intraretinal fluid segmentation</div></h4>
		<image src="./img/unet-vs-humans.png" height="500px">
			<div style="position: absolute; left: 700px; top: 620px" >
				<small><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5508840/">Lee, Tyring, Deruyter, Wu, Rokem & Lee (2016)<br> Biomed opt Express</a>
				</small>
			</div>
	</section>

	<section>
		<h3>Segmenting experimental data: </h3>
		<h3>oxygen induced retinopathy</h3>
		<img src="img/oir_retina.jpg" height="400">
		<br>
		Retinal segmentation
		<div class="cite" style="font-size:14px">
			<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752269/">Xiao, Bucher, Wu, Rokem, Lee, Marra, Fallon, Diaz-Aguilar, Aguilar, Friedlander & Lee (2017), JCI Insight</a>

		</div>
	</section>

	<section>
		<h3>Segmenting experimental data: </h3>
		<h3>oxygen induced retinopathy</h3>
		<img src="img/oir_vasoobliteration.jpg" height="400">
		<br>
		The vaso-obliteration zone
		<div class="cite" style="font-size:14px">
			<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752269/">Xiao, Bucher, Wu, Rokem, Lee, Marra, Fallon, Diaz-Aguilar, Aguilar, Friedlander & Lee (2017), JCI Insight</a>

		</div>
	</section>


	<section>
		<h3>Segmenting experimental data: </h3>
		<h3>oxygen induced retinopathy</h3>
		<img src="img/oir_neovascular.jpg" height="400">
		<br>
		The neovascular tufts
		<div class="cite" style="font-size:14px">
			<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5752269/">Xiao, Bucher, Wu, Rokem, Lee, Marra, Fallon, Diaz-Aguilar, Aguilar, Friedlander & Lee (2017), JCI Insight</a>

		</div>
	</section>



		<section>
		<h2>The solution</h2>
		<p>Expert => results</p>
		<p>Expert => training data => machine learning => results</p>
		<p class="fragment">But: for many tasks, not enough training data</p>
		<p class="fragment">=> Amplify labeled data-sets with citizen science</p>
		<p class="fragment">Expert => citizen science => training data => machine learning => results</small></p>

	</section>

	<section>
		<h2>Scaling expertise with citizen science</h2>
		<div style="position: absolute; left:200px; top:60px;">
			<img src="img/anisha.jpg" height="300">
			<br>
			Anisha Keshavan
		</div>

		<div style="position: absolute; left:420px; top:60px;">
			<img src="img/jason.jpg" height="300">
			<br>
			Jason Yeatman
		</div>
	</section>



		<section>
		<h2>Example</h2>
		<h3 >Quality control of T1-weighted images</h3>
		<img src="img/t1_qc.png" height="300">
		<div class="cite">
			<a href="https://www.nature.com/articles/sdata2017181">Healthy Brain Network <br>(Alexander et al. 2017)</a>
		</div>
	</section>

	<section>
		<h4><a href="https://braindr.us">https://braindr.us</a></h4>

		<img src="img/braindr.gif">

		<div class="cite">
			<a href="">Keshavan, Yeatman & <br> Rokem (<em>in prep</em>)</a>
		</div>

	</section>

	<section>
		<h2>Braindr</h2>
		<div style="position: absolute; left:200px; top:10px;">
			<blockquote class="twitter-tweet" data-lang="en">
				<p lang="en" dir="ltr">Are you at work but feel like playing Tinder? Why not play braindr (<a href="https://t.co/yXw191Q7Hy">https://t.co/yXw191Q7Hy</a>) instead, and help neuroscientists rate the quality of brain images? Swipe left to fail bad quality images! Built with <a href="https://twitter.com/vuejs?ref_src=twsrc%5Etfw">@vuejs</a> and <a href="https://twitter.com/Firebase?ref_src=twsrc%5Etfw">@Firebase</a> <a href="https://twitter.com/hashtag/citizenscience?src=hash&amp;ref_src=twsrc%5Etfw">#citizenscience</a> <a href="https://t.co/tpI9Y3UKOb">pic.twitter.com/tpI9Y3UKOb</a></p>&mdash; anisha (@akeshavan_)
				<a href="https://twitter.com/akeshavan_/status/961385285182353408?ref_src=twsrc%5Etfw">February 7, 2018</a></blockquote>
			<script async src="https://platform.twitter.com/widgets.js" charset="utf-8"></script>
		</div>
		<div class="cite">
			<a href="">Keshavan, Yeatman & <br> Rokem (<em>in prep</em>)</a>
		</div>
	</section>

	<section>
		<h2>Multiple ratings per image</h2>
		<img src="img/braindr_ratings_per_img.png" height="500">
		<div class="cite">
			<a href="https://akeshavan.github.io/braindr-results/#/">Keshavan, Yeatman & <br> Rokem (<em>in prep</em>)</a>
		</div>

	</section>

	<section>
		<h2>But often, no agreement</h2>
		<img src="img/braindr_average_rating.png" height="500">
		<div class="cite">
			<a href="https://akeshavan.github.io/braindr-results/#/">Keshavan, Yeatman & <br> Rokem (<em>in prep</em>)</a>
		</div>
	</section>

	<section>
		<h2>Aggregating across raters</h2>
		XGBoost (<a href="http://www.kdd.org/kdd2016/papers/files/rfp0697-chenAemb.pdf">Chen & Guestrin, 2016</a>)
		<img src="img/braindr_rater_importance.png" height="500">
		<br>
		<div class="cite">
			<a href="https://akeshavan.github.io/braindr-results/#/">Keshavan, Yeatman & <br> Rokem (<em>in prep</em>)</a>
		</div>
	</section>

	<section>
		<h2>Aggregating across raters</h2>
		<img src="img/braindr_rater_importance_per_trials.png" height="500">
		<div class="cite">
			<a href="https://akeshavan.github.io/braindr-results/#/">Keshavan, Yeatman & <br> Rokem (<em>in prep</em>)</a>
		</div>
	</section>


	<section>
		<h2>Aggregating across raters</h2>
		<img src="img/braindr_xgboost_ratings.png" height="500">
		<div class="cite">
			<a href="https://akeshavan.github.io/braindr-results/#/">Keshavan, Yeatman & <br> Rokem (<em>in prep</em>)</a>
		</div>
	</section>



	<section>
		<h2>Aggregating across raters</h2>
		<img src="img/braindr_xgboost_results.png" height="500">
		<div class="cite">
			<a href="https://akeshavan.github.io/braindr-results/#/">Keshavan, Yeatman & <br> Rokem (<em>in prep</em>)</a>
		</div>
	</section>

	<section>
		<h2>How do we scale this up?</h2>
	</section>


	<section>
		<h2>Scaling expertise using citizen scientist ratings</h2>
		<img src="img/braindr_learning_curves.png" height="500">
		<div class="cite">
			<a href="https://akeshavan.github.io/braindr-results/#/">Keshavan, Yeatman & <br> Rokem (<em>in prep</em>)</a>
		</div>
	</section>


	<section>
		<h2>Scaling expertise using citizen scientist ratings</h2>
		<img src="img/braindr_final_rocs.png" height="500">
		<div class="cite">
			<a href="https://akeshavan.github.io/braindr-results/#/">Keshavan, Yeatman & <br> Rokem (<em>in prep</em>)</a>
		</div>
	</section>


	<section>
		<h2>Summary</h2>
		<p>When there is enough training data: deep learning</p>
		<p>When we need to scale up: citizen scientists</p>
		<p>Model of expertise (random forest) for aggregation</p>
		<p>Model of perception (neural network) for automation and scaling</p>
	</section>

	<section>
		<h2>Future applications</h2>
		<p class="fragment">Other tasks</p>
		<p class="fragment">Tumor segmentation in MRI</p>
		<p class="fragment">Other types of data and other procedures</p>
	</section>


	<section>
		<h2>Challenges</h2>
		<p class=>Methods that work in standard use may not apply to large datasets</p>
		<p class>=> Train machine learning algorithms to replace expert decision making</p>
		<p class="fragment">Tools are needed for data exploration and transparent sharing of results</p>
		<p class="fragment">=> Build browser-based applications for exploratory data analysis and data sharing </p>
	</section>


	<section>
		<h3>Challenge: tools for exploration of complex data</h3>
		<p class="fragment">Results from large datasets are hard to understand </p>
		<p class="fragment">Hard to communicate</p>
		<p class="fragment">Hard to reproduce</p>
		<p class="fragment">Data sharing is not incentivized and is not easy enough</p>
	</section>

	<section>
		<h4>Normal behavior is supported by brain connectivity</h4>
		<img src="./img/OldenDays.png" height="505">
		<div class="cite">
			Image from <br><a href="https://www.ncbi.nlm.nih.gov/pubmed/16141282">Catani and ffytche (2015)</a>
		</div>
	</section>

	<section>
		<img src="./img/optic-radiation-postmortem.png" height="505" >
	</section>

	<section>
		<h3>Not just passive cables</h3>
		<p class="fragment">Brain connections develop and mature with age</p>
		<p class="fragment">Individual differences account for differences in behaviour</p>
		<p class="fragment">Adapt and change with learning</p>
	</section>
	<!--
	<section>
		<div style="position: absolute; left: 100px;">
			<img src="./img/optic-radiation-postmortem.png" height="505" >
		</div>

		<div class="fragment" style="position: absolute; left: 500px;">

			<img src="./img/nerve-fiber.png" height="505" >
		</div>

	</section>
	-->
	<section>
		<h4>Diffusion MRI</h4>
		<div class = "fragment fade-in" style="position: absolute">
			<canvas id="arrows-iso-horiz" width="1000" height="1000">
			</canvas>
			<script>
				context = document.getElementById('arrows-iso-horiz').getContext("2d");
				context.beginPath();
				canvas_arrow_two_heads(context, 390, 450, 590, 450);
				context.lineWidth = 2;
				context.stroke();
			</script>
		</div>
		<div class = "fragment fade-in" style="position: absolute">
			<canvas id="arrows-iso-vert" width="1000" height="1000">
			</canvas>
			<script>
				context = document.getElementById('arrows-iso-vert').getContext("2d");
				context.beginPath();
				canvas_arrow_two_heads(context, 250, 350, 250, 150);
				context.lineWidth = 2;
				context.stroke();
			</script>
		</div>

		<div class="fragment" text-align: left>
			Isotropic diffusion
		</div>
		<video width="600" autoplay loop>
			<source src="./img/diffusion-isotropic.mp4">
		</video>

		<div style="position: absolute; left: 600px; top: 600px" >
			<small><a href="http://jov.arvojournals.org/article.aspx?articleid=2603187">Rokem et al. (2017), Journal of Vision</a></small>
			<br>
			<small><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0123272">Rokem et al. (2015), PLoS One</a></small>
		</div>

	</section>

	<section>
		<h4>Diffusion MRI</h4>
		<div class = "fragment fade-in" style="position: absolute">
			<canvas id="arrows-aniso-vert" width="1000" height="1000">
			</canvas>
			<script>
				context = document.getElementById('arrows-aniso-vert').getContext("2d");
				context.beginPath();
				canvas_arrow_two_heads(context, 250, 325, 250, 175);
				context.lineWidth = 2;
				context.stroke();
			</script>
		</div>
		<div class = "fragment fade-in" style="position: absolute">
			<canvas id="arrows-aniso-horiz" width="1000" height="1000">
			</canvas>
			<script>
				context = document.getElementById('arrows-aniso-horiz').getContext("2d");
				context.beginPath();
				canvas_arrow_two_heads(context, 370, 400, 610, 400);
				context.lineWidth = 2;
				context.stroke();
			</script>
		</div>

		<div class="fragment" text-align:left;>
			Anisotropic diffusion
		</div>
		<video width="600" autoplay loop>
			<source src="./img/diffusion-anisotropic.mp4">
		</video>
		<div style="position: absolute; left: 600px; top: 600px" >
			<small><a href="http://jov.arvojournals.org/article.aspx?articleid=2603187">Rokem et al. (2017), Journal of Vision</a></small>
			<br>
			<small><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0123272">Rokem et al. (2015), PLoS One</a></small>
		</div>
	</section>

	<!--
	<section>

		<div class = "fragment fade-out" style="position: absolute; left: 100px;">
			<img src="./img/optic-radiation-postmortem.png" height="505" >
		</div>

		<div style="position: absolute; left: 500px;">
			<img src="./img/nerve-fiber.png" height="505" >
		</div>

		<div class = "fragment fade-in" style="position: absolute">
			<canvas id="fiber-arrow-horiz" width="1000" height="1000">
			</canvas>
			<script>
				context = document.getElementById('fiber-arrow-horiz').getContext("2d");
				context.beginPath();
				canvas_arrow_two_heads(context, 630, 600, 800, 600);
				context.lineWidth = 2;
				context.stroke();
			</script>
		</div>

		<div class = "fragment fade-in" style="position: absolute">
			<canvas id="fiber-arrow-vert" width="1000" height="1000">
			</canvas>
			<script>
				context = document.getElementById('fiber-arrow-vert').getContext("2d");
				context.beginPath();
				canvas_arrow_two_heads(context, 450, 100, 450, 400);
				context.lineWidth = 2;
				context.stroke();
			</script>
		</div>

	</section>
	-->

	<section>
		<h4>Diffusion MRI</h4>
		<video width="600" autoplay loop>
			<source src="./img/dMRI-signal-movie.mp4">
		</video>
		<div style="position: absolute; left: 600px; top: 600px" >
			<small><a href="http://jov.arvojournals.org/article.aspx?articleid=2603187">Rokem et al. (2017), Journal of Vision</a></small>
			<br>
			<small><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0123272">Rokem et al. (2015), PLoS One</a></small>
		</div>
	</section>


	<section>
		<h4>Diffusion statistics</h4>
		<div class="fragment" style="position: absolute; left: 14px;">
			<img src="img/tensor-stats1.png" height="400"  >
			<div style="position: absolute; left: 75px; top: 420px;">
				<small>Mean diffusivity</small>
			</div>
			<div style="position: absolute; left: -8px;">
				<img src="img/md-scale.png" height="40" >
			</div>
			<div style="position: absolute; left: 222px; top:432px; ">
				<img src="img/md-units.png" height="50" >
			</div>
		</div>
		<div class="fragment fade-in" style="position: absolute; left: 7px;">
			<img src="img/tensor-stats2.png" height="400"  >

			<div style="position: absolute; left: 350px; top:432px; ">
				<video width="200" autoplay loop>
					<source src="./img/diffusion-fa-251.mov">
			</div>

			<div style="position: absolute; left: 350px; top: 420px;">
				<small>Fractional anisotropy</small>
			</div>

		</div>
		<div class="fragment fade-in" style="position: absolute; left: 0px;">
			<img src="img/tensor-stats3.png" height="400"  >
			<div style="position: absolute; left: 600px; top: 420px;">
				<small>Principal diffusion direction</small>
			</div>
			<div style="position: absolute; left: 700px; top:432px; ">
				<img src="img/axes.png" height="100" >
			</div>
		</div>
		<div style="position: absolute; left: 600px; top: 640px" >
			<small><a href="http://jov.arvojournals.org/article.aspx?articleid=2603187">Rokem et al. (2017), Journal of Vision</a></small>
			<br>
			<small><a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0123272">Rokem et al. (2015), PLoS One</a></small>
		</div>
	</section>

	<!--
	<section>
		<h2>Automated Fiber Quantification (AFQ)</h2>
		<img src="img/afq1.png" height="420">

		<div class="cite">
			<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0049790">Yeatman et al. (2012)</a>
		</div>
	</section>
	-->
	<section>
		<img align="center" src="img/pyafq_segmentation1.gif" height="500">
	</section>

	<!--
	<section>
		<h2>Automated Fiber Quantification (AFQ)</h2>
		<img src="img/afq2.png" height="420">

		<div class="cite">
			<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0049790">Yeatman et al. (2012)</a>
		</div>
	</section>
	-->
	<!--
	<section>
		<h2>Automated Fiber Quantification (AFQ)</h2>
		<img src="img/afq3.png" height="420">

		<div class="cite">
			<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0049790">Yeatman et al. (2012)</a>
		</div>
	</section>

	<section>
		<h2>Automated Fiber Quantification (AFQ)</h2>
		<img src="img/afq4.png" height="420">

		<div class="cite">
			<a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0049790">Yeatman et al. (2012)</a>
		</div>
	</section>

	<section>
		<h2>Challenges</h2>
		<p class="fragment">Mass univariate analysis</p>
		<p class="fragment">ROI-based analysis</p>
	</section>
	-->

	<section>

		<img align="center" src="img/pyafq_segmentation2.gif" height="500">

	</section>

	<section>
		<h2>Amyotrophic Lateral Sclerosis (ALS)</h2>
		<img src="img/sarica_results.png" height="300px">
		<p class="fragment">Classify patients based on the tissue properties in this part of the brain</p>
		<p class="fragment">Random Forest algorithm => 80% accuracy</p>
		<div class="cite">
			<a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23412">Sarica et al. (2017)</a>
		</div>

	</section>

	<section>
		<h2>How could we improve on this?</h2>
		<em class="fragment">If we can't get the data?</em>

	</section>

	<section id="afq-browser">
		<h3>Challenge: improved data exploration and data sharing</h3>
		<div style="position: absolute; left:70px; top:60px;">
			<img src="img/jason.jpg" height="200">
			<br>
			Jason Yeatman
		</div>
		<div style="position: absolute; left:280px; top:60px;">
			<img src="img/adam.jpeg" height="200">
			<br>
			Adam <br>Richie-Halford
		</div >
		<div style="position: absolute; left:490px; top:60px;">
			<img src="img/josh.png", height="200">
			<br>
			Josh Smith
		</div>
		<div style="position: absolute; left:705px; top:60px;">
			<img src="img/anisha.jpg", height="200">
			<br>
			Anisha <br> Keshavan
		</div>
	</section>

	<section>
		<h2>The solution</h2>
		<p class="fragment">A web-based application</p>
		<p class="fragment">Builds a web-site for a diffusion MRI dataset</p>
		<p class="fragment">Automatically uploads the website to Github</p>
		<div class="cite">
			<a href="https://www.nature.com/articles/s41467-018-03297-7">Yeatman, Richie-Halford, Smith, Keshavan & Rokem (2018)<br> Nature Communications</a>
		</div>
	</section>


	<section>
		<h3><a href="https://yeatmanlab.github.io/Sarica_2017">https://yeatmanlab.github.io/Sarica_2017</a></h3>

		<video width="800" autoplay loop>
			<source src="./img/afq-browser-demo.mp4">
		</video>

		<div class="cite">
			<a href="https://www.nature.com/articles/s41467-018-03297-7">Yeatman, Richie-Halford, Smith, Keshavan & Rokem (2018)<br> Nature Communications</a>
		</div>

	</section>
	<section>
		<h2> Exploratory data analysis</h2>

		<p class="fragment">Enhances published results<p>
		<p class="fragment">Linked visualizations facilitate easy exploration</p>
		<p class="fragment">Enables new discoveries in old datasets</p>

		<div class="cite">
			<a href="https://www.nature.com/articles/s41467-018-03297-7">Yeatman, Richie-Halford, Smith, Keshavan & Rokem (2018)<br> Nature Communications</a>
		</div>

	</section>

	<section>
		<h2>Automatic data sharing</h2>

		<img src="./img/afq-browser-static.png" width="800px">

		<div class="cite">
			<a href="https://www.nature.com/articles/s41467-018-03297-7">Yeatman, Richie-Halford, Smith, Keshavan & Rokem (2018)<br> Nature Communications</a>
		</div>

		<svg class="fragment" width="400" height="110"  style="position: absolute; left:435px; top:500px;">
			<rect rx="10" ry="10" width="150" height="60" style="fill:yellow;stroke-width:3;stroke:rgb(1,0,0);opacity:0.4;" />
		</svg>

		<svg class="fragment" width="400" height="110"  style="position: absolute; left:780px; top:150px;">
			<rect rx="10" ry="10" width="100" height="60" style="fill:yellow;stroke-width:3;stroke:rgb(1,0,0);opacity:0.4;" />
		</svg>

	</section>


	<section>
		<h2>Further exploration</h2>

		<video width="800" autoplay loop>
			<source src="./img/afq-browser-binder-demo.mp4">
		</video>

		<div class="cite">
			<a href="https://www.nature.com/articles/s41467-018-03297-7">Yeatman, Richie-Halford, Smith, Keshavan & Rokem (2018)<br> Nature Communications</a>
		</div>

	</section>

	<section>
		<h2>Summary</h2>
		<p class="fragment">Exploratory data analysis</p>
		<p class="fragment">Automated data sharing</p>
		<p class="fragment">Dimensionality reduced data in tidy table format</p>
		<div class="cite">
			<a href="https://www.nature.com/articles/s41467-018-03297-7">Yeatman, Richie-Halford, Smith, Keshavan & Rokem (2018)<br> Nature Communications</a>
		</div>
	</section>

	<section>
		<h2>Future applications</h2>
		<p>Other analysis pipelines</p>
		<p>Dimensionality reduction in multi-channel neural recordings</p>
	</section>


	<section>
		<h2>Challenges</h2>
		<p>Methods that work in standard use may not apply to large datasets</p>
		<p>=> Train machine learning algorithms to replace expert decision making</p>
		<p>Tools are needed for data exploration and transparent sharing of results</p>
		<p>=> Build browser-based applications for exploratory data analysis and data sharing </p>
		<p class="fragment">Algorithms are needed to extract information from complex high-dimensional data</p>
		<p class="fragment">=> Translate statistical techniques into practice in neuroscience</p>
	</section>


		<section id="afq-insight">
	<h3>Opportunity: data-driven discovery</h3>
	<div style="position: absolute; left:40px; top:80px;">
	<img src="img/adam.jpeg" height="300">
		<br>
		Adam Richie-Halford
	</div >
	<div style="position: absolute; left:350px; top:80px;">
	<img src="img/noah.jpg", height="300">
		<br>
		Noah Simon
	</div>
	<div style="position: absolute; left:600px; top:80px;">
	<img src="img/jason.jpg" height="300">
	<br>
	Jason Yeatman
	</div>
	</section>


	<section>
		<h2>Diffusion MRI data has group structure</h2>
		<img src="img/sgl_design.png" height="500px">
	</section>

	<section>
		<h2>Logistic regression</h2>
		<img src="img/logistic_regression.png" width="600px">
		<p class="fragment">But in our case p (number of variables) >> n (number of subjects) </p>
	</section>

	<section>
		<h2>The Lasso</h2>
		<img src="img/lasso_penalty.png" width="400px">
		<p class="fragment">Enforces sparsity</p>
		<p class="fragment">But ignores group structure in the data</p>
		<p class="fragment">Accuracy: ~71% (AUC: ~71%)</p>
		<p class="fragment">Does not discover the right features</p>
		<p class="fragment">Top 10 features include some CST, but also other parts of the brain</p>
	<div class="cite">
		<a href="http://statweb.stanford.edu/~tibs/lasso/lasso.pdf">Tibshirani (1996)</a>
	</div>
	</section>

	<section>
		<h2>The Group Lasso</h2>
	<img src="img/group_lasso_penalty.png" width="600px">
	<p>Where <em>l</em> are groups of variables </p>
	<p><em>p(l)</em> is the number of variables in group <em>l</em></p>
	<p>In our case: all the measurements of a tissue propetry within a tract</p>
	<p class="fragment">Enforces selection of groups</p>
	<p class="fragment">But does not enforce L1 sparsity within included groups</p>
	<div class="cite">
		<a href="http://www.columbia.edu/~my2550/papers/glasso.final.pdf">Yuan and Lin (2006)</a>
	</div>
	</section>
	<section>
		<h2>Sparse Group Lasso</h2>
		<img src="img/sparse_group_lasso_penalty.png" width="600px">
		<p>Enforces sparsity both at the group level and the within-group level</p>
		<p>Subsumes the Lasso (&lambda;<sub>1</sub> = 0)</p>
		<p>And the Group Lasso (&lambda;<sub>2</sub> = 0)</p>
		<p class="fragment">But more meta-parameters</p>
		<div class="cite">
			<a href="https://www.tandfonline.com/doi/abs/10.1080/10618600.2012.681250">Simon et al. (2013)</a>
		</div>
	</section>

	<section>
		<h2>Fitting meta-parameters</h2>
		<p >Nested cross-validation</p>
		<img src="img/NestedCrossValidation1.png" height="500px">


	</section>
	<section>
		<h2>Fitting meta-parameters</h2>
		<p >Nested cross-validation</p>
		<img src="img/NestedCrossValidation2.png" height="500px">


	</section>
	<section>
		<h2>Fitting meta-parameters</h2>
		<p >Nested cross-validation</p>
		<img src="img/NestedCrossValidation3.png" height="500px">

	</section>

	<section>
		<h2> Accurate classification and feature detection</h2>
		<img src="img/sgl_result.png" height="300px">
		<p>Classification accuracy of ~84% (AUC of 0.9)</p>
		<p>Top 10 features selected include CST</p>
		<div class="cite">
			<a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/hbm.23412">Sarica et al. (2017)</a>
		</div>

	</section>

	<section>
	<h2>Summary</h2>
		<p class="fragment">Sparse Group Lasso accurately discovers structure in dMRI data</p>
		<p class="fragment">Classification of disease states</p>
		<p class="fragment">In a regression setting, prediction of continuous measures <br> (e.g, "brain age", IQ, reading skills)</p>
	</section>

	<section>
		<h2>Future applications</h2>
		<p>Multi-region, multi-neuron recordings</p>
		<div class="fragment">
		<p>Neurons => features</p>
		<p>Brain regions => groups</p>
		<p>Trials => observations</p>
		</div>
	</section>

	<section>
		<h2>Multi-neuron recordings also have group structure</h2>
		<img src="img/sgl_design.png" height="500px">
	</section>

	<!--

	<section>
		<h2>Challenge:large scale computing</h2>
		<p class="fragment">Solution: the cloud</p>
		<p class="fragment">Infinitely scalable</p>
		<p class="fragment">"Elastic"</p>
		<p class="fragment">But the cloud is hard to operate</p>

	</section>

	<section>
		<h2>Challenge: accessible cloud computing</h2>

		<div style="position: absolute; left:350px; top:60px;">
			<img src="img/adam.jpeg" height="300">
			<br>
			Adam Richie-Halford
		</div >

	</section>

	<section>
		<h2>Cloudknot: package your code and run it on AWS Batch</h2>

		<img src="img/cloudknot_workflow.png" height="500">
	<div class="cite">
			<a href="">Richie-Halford and Rokem (submitted)</a>

	</div>
	</section>

		<section>
			<h2>Cloudknot: package your code and run it on AWS Batch</h2>

			<img src="img/mri_benchmark.png" height="400">

			<div class="cite">
				<a href="http://www.vldb.org/pvldb/vol10/p1226-mehta.pdf">Mehta et al. (2017)</a>
			</div>
		</section>

	-->
	<section>
		<h2>Challenges</h2>
		<p>Methods that work in standard use may not apply to large datasets</p>
		<p>=> Train machine learning algorithms to replace expert decision making</p>
		<p>Tools are needed for data exploration and transparent sharing of results</p>
		<p>=> Build browser-based applications for exploratory data analysis and data sharing </p>
		<p>Algorithms are needed to extract information from complex high-dimensional data</p>
		<p>=> Translate statistical techniques into practice in neuroscience</p>
		<p class="fragment">Sociotechnical structures are strained: collaboration, publication, training</p>
		<p class="fragment">=> Open source software collaborations and science-focused hack weeks</p>
	</section>

	<section>
	<h4>Open source software is a necessary complement to brain observatories</h4>
		<p>Required for reproducibility</p>
		<p>Enables building on previous work</p>

	</section>

	<section>
		Deep learning projects:
		<br>
		<a href="https://github.com/uw-biomedical-ml/irf-segmenter">https://github.com/uw-biomedical-ml/irf-segmenter</a>
		<br>
		<a href="https://github.com/uw-biomedical-ml/oir"> https://github.com/uw-biomedicasl-ml/oir</a>
		<br>
		<br>
		Braindr:
		<br>
		<a href="https://github.com/akeshavan/braindr-analysis">https://github.com/akeshavan/braindr-analysis</a>
		<br>
		<br>
		AFQ-Browser:
		<br>
		<a href="https://github.com/yeatmanlab/pyAFQ">https://github.com/yeatmanlab/pyAFQ</a>
		<br>
		<a href="https://github.com/yeatmanlab/AFQ-Browser">https://github.com/yeatmanlab/AFQ-Browser</a>
		<br>
		<br>
		Sparse Group Lasso:
		<br>
		<a href="https://github.com/richford/AFQ-Insight">https://github.com/richford/AFQ-Insight</a>
	</section>

	<section>
		<h2> Open source diffusion MRI</h2>
		<img src="img/dipy-logo.png">
		<br>
		Comprehensive
		<br>
		Thoroughly tested
		<br>
		Well-documented
		<br>
		<!--
		<br>
		<img src="img/eleftherios.jpg" height="200">
		<br>
		Eletherios Garyfallidis (Indiana University)
		-->
		<div class="cite" style="font-size:14px">
			<a href="https://www.frontiersin.org/articles/10.3389/fninf.2014.00008/full">Garyfallidis, Brett, Amirbekian, Rokem, van der Walt, Descoteaux, Nimmo Smith, and DIPY contributors (2014) <br> Frontiers in Neuroinformatics</a>
		</div>
	</section>

	<section>
		<h2>Open to users</h2>
		<img src="img/dipy_users.png">
		<div class="cite" style="font-size:14px">
			<a href="https://www.frontiersin.org/articles/10.3389/fninf.2014.00008/full">Garyfallidis, Brett, Amirbekian, Rokem, van der Walt, Descoteaux, Nimmo Smith, and DIPY contributors (2014) <br> Frontiers in Neuroinformatics</a>
		</div>
	</section>

	<section>
		<h2>Open to contributors</h2>
		<img src="img/dipy_contributors.png">
		<div class="cite" style="font-size:14px">
			<a href="https://www.frontiersin.org/articles/10.3389/fninf.2014.00008/full">Garyfallidis, Brett, Amirbekian, Rokem, van der Walt, Descoteaux, Nimmo Smith, and DIPY contributors (2014) <br> Frontiers in Neuroinformatics</a>
		</div>
	</section>

	<section>
		<h2>Distributed collaboration</h2>
		<img src="img/dipy_global.png">
		<div class="cite" style="font-size:14px">
		<a href="https://www.frontiersin.org/articles/10.3389/fninf.2014.00008/full">Garyfallidis, Brett, Amirbekian, Rokem, van der Walt, Descoteaux, Nimmo Smith, and DIPY contributors (2014) <br> Frontiers in Neuroinformatics</a>
		</div>
	</section>

	<!--
	<section>
		<a href="http://joss.theoj.org/"></a><img src="img/JOSS_banner.png" height="300">
		<h3>Rigorously evaluate open source software</h3>
		<h3>Provide a canonical citation for software that meets these standards</h3>
	</section>
	-->
	<section>
		<h2>Challenge: training</h2>

	    <p class="fragent">Methods in data science are rapidly changing</p>
		<p class="fragment">Learning often require substantial hands-on experience</p>
		<p class="fragment">=> Hack weeks</p>
		<p class="fragment">Week-long events</p>
		<p class="fragment">Combination of learning and project work</p>
		<p class="fragment">Participant driven</p>
		<p class="fragment">Astrohackweek</p>
		<p class="fragment">Neurohackweek</p>
		<p class="fragment">Geohackweek</p>
		<div class="cite">
			<a href="https://arxiv.org/abs/1711.00028"> Huppenkothen, Arendt, Hogg, Ram, Vanderplas & Rokem <br>(<em>in review, PNAS</em>)</a>

		</div>

	</section>

		<section>
			<h3>A fine balance of pedagogy and hacking</a></h3>
			<img src="img/HackSpectrum.png" height="400">
			<div class="cite">
				<a href="https://arxiv.org/abs/1711.00028"> Huppenkothen, Arendt, Hogg, Ram, Vanderplas & Rokem <br>(<em>in review, PNAS</em>)</a>

			</div>
		</section>

		<!--

		<div style="position: absolute; left:120px; top:10px;">
		<img src="img/tal.jpg" height="300px">
		</div>

		<div style="position: absolute; left:450px; top:10px;">
			<img src="img/daniela.png" height="300px">
		</div>

		<div class="cite">
			<a href="https://arxiv.org/abs/1711.00028">Huppenkothen et al. (under review)</a>
		</div>
		-->

	<section>
		<h2><a href="http://neurohackademy.org/">Neurohackademy</a></h2>
		<br>
		A Summer Institute in Neuroscience and Data Science (=> 2021)
		<img src="img/joy_of_hacking.png" height="400">

	</section>



	<section>

		<h2> Thanks! </h2>
		<div style="position: absolute; left:100px; top:100px;" align="left">
			Sa Xiao
			<br>
			Aaron Lee
			<br>
			Parmita Mehta
			<br>
			Magda Balazinska
			<br>
			Jason Yeatman
			<br>
			Adam Richie-Halford
			<br>
			Josh Smith
			<br>
			Anisha Keshavan
			<br>
			Noah Simon
			<br>
			Eleftherios Garyfallidis (IU)
			<br>
			Tal Yarkoni (UT Austin)
			<br>
			Daniela Huppenkothen
			<br>
			Anthony Arendt
		</div>

		<div style="position: absolute; left:500px; top:80px;">
			<img src="img/msdse-sponsors.png" height="100px">
			<br>
			<img src="img/nimh-logo.gif" height="100px">
			<br>
			<img src="img/BMGF-logo.png" height="100px">
			<img src="img/nsf-logo.jpeg" height="100px">
			<br>
			<img src="img/uwin-logo.jpg" height="80px">
			<img src="img/eScience.png" height="80px">
		</div>

	</section>

	<section data-background-image="./img/portage-bay.jpg" data-background-size="cover" style="background: rgba(255, 255, 255, 0.8);">
		<blockquote>
			<img src="img/eScience.png" width="800px">
			<small><em>"All across our campus, the process of discovery will increasingly rely on researchersâ€™ ability to extract knowledge from vast amounts of data... In order to remain at the forefront, UW must be a leader in advancing these techniques and technologies, and in making [them] accessible to researchers in the broadest imaginable range of fields"</em></small>
		</blockquote>
	</section>


	<section>

			<div style="position:absolute; left: 200px; top:-120px;">
			<h2>Contact information</h2>
			</div>
			<div style="position:absolute; left: 220px; top:-50px;">
			<img src="img/globe-xxl.png" width="100px;" >
			<div style="position:absolute; left: 120px; top:40px;">http://arokem.org
			</div>
			</div>
			<div style="position:absolute; left: 220px; top:70px;">
			<img src="img/email-11-xxl.png" width="100px;" >
			<div style="position:absolute; left: 120px; top:40px;">arokem@gmail.com
			</div>
			</div>
			<div style="position:absolute; left: 220px; top:190px;">
			<img src="img/twitter-xxl.png" width="100px;" >
			<div style="position:absolute; left: 120px; top:40px;">@arokem
			</div>
			</div>
			<div style="position:absolute; left: 220px; top:310px;">
			<img src="img/github-6-xxl.png" width="100px;" >
			<div style="position:absolute; left: 120px; top:40px;">github.com/arokem
			</div>
			</div>

	</section>

	</div>
	</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>
			// More info about config & dependencies:
			// - https://github.com/hakimel/reveal.js#configuration
			// - https://github.com/hakimel/reveal.js#dependencies
			Reveal.initialize({
				history: true,
				controls: false,
				progress: true,
				center: true,

				transition: 'fade', // none/fade/slide/convex/concave/zoom

				dependencies: [
					{ src: 'plugin/markdown/marked.js' },
					{ src: 'plugin/markdown/markdown.js' },
					{ src: 'plugin/notes/notes.js', async: true },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } }
				]
			});
		</script>

	</body>
</html>
